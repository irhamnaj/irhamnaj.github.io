---
published: false
title: Customer Segmentation and Market Basket Analysis on Online Retail
collection: ml
layout: single
author_profile: false
read_time: true
categories: [project]
header :
    teaser : "https://irhamnaj.github.io/assets/images/customer-segmentation.png"
comments : true
toc: true
toc_sticky: true
sidebar:
    nav: sidebar-sample
---

A small startup can afford to target users based on some rules like demographics. But, for companies with sizes as same as Tokopedia and Bukalapak with million daily customers and transaction. they have got to graduate to a more sophisticated method to target their marketing.

One such approach is  Cluster Analysis, Use mathematical methods to discover groups of similar customers based on many criteria such as customer daily habit, demographic, economic condition, and other characteristics.

One major purpose of the above approach is to get the right cluster (group) of data that can be used by marketing team to maximize the company budget for marketing campaigns like discounts or product offers. In this Project, I will then use RFM Analysis and the k-means unsupervised Machine Learning algorithm to group these customers into clusters. 

# dataset Overview
The dataset includes one years of customer data (between december 2010 s/d december 2011), including their purchasing habits and demographic.

here, the information of each columns:
- InvoiceNo: Invoice number. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation.
- StockCode: Product (item) code. A 5-digit integral number uniquely assigned to each distinct product.
- Description: Product (item) name.
- Quantity: The quantities of each product (item) per transaction.
- InvoiceDate: Invice date and time.The day and time when a transaction was generated.
- UnitPrice: Unit price. Product price per unit in sterling (Â£).
- CustomerID: Customer number. A 5-digit integral number uniquely assigned to each customer.
- Country: Country name. The name of the country where a customer resides.

# Problem Statement
Online retail A has million customer transactions on their website that cust across demographics and has very different Purchasing habits. Our goal is to tackle this complexity and automatically segment customers into groups that respond best to a particular marketing campaign.

# Metrics
Unlike Supervised Machine learning, Unsupervised machine learning models don't have clearly metrics to find optimal parameters such as the number of clusters in k-means. But we can use Elbow and Silhouette methods to analyze number of clusters and find best number of clusters.

# Data Wrangling
## Import Library

```python
# library for data analysis
import pandas as pd
import numpy as np

# library for visualization
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib import ticker
import seaborn as sns

# datetime manipulation
import datetime, nltk, warnings

#intertools
import itertools


#library statistics
from scipy import stats
from scipy.stats import norm
from scipy.stats import skew
from scipy.stats import kurtosis
from scipy.spatial.distance import cdist

#library for market basket analysis
from mlxtend.frequent_patterns import apriori as ap
from mlxtend.frequent_patterns import association_rules

# No warnings about setting value on copy of slice
pd.options.mode.chained_assignment = None


from pathlib import Path

#library for machine learing
from sklearn.preprocessing import PowerTransformer, StandardScaler
from sklearn.cluster import KMeans

#metrics
from sklearn.metrics import silhouette_samples, silhouette_score
```
## Read dataset
you can use pd.read_excel to read data with format xlsx, then use shape to know the dimension of the data

```python
#read_dataset
df = pd.read_excel('/content/drive/My Drive/Online Retail.xlsx', parse_dates=['InvoiceDate'])

#dataset overview
print('data has {} observations and {} features'.format(df.shape[0], df.shape[1]))
print("data overview")
df.head()
```
data has 541909 observations and 8 features
data overview
|    |   InvoiceNo | StockCode   | Description                         |   Quantity | InvoiceDate         |   UnitPrice |   CustomerID | Country        |
|---:|------------:|:------------|:------------------------------------|-----------:|:--------------------|------------:|-------------:|:---------------|
|  0 |      536365 | 85123A      | WHITE HANGING HEART T-LIGHT HOLDER  |          6 | 2010-12-01 08:26:00 |        2.55 |        17850 | United Kingdom |
|  1 |      536365 | 71053       | WHITE METAL LANTERN                 |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |
|  2 |      536365 | 84406B      | CREAM CUPID HEARTS COAT HANGER      |          8 | 2010-12-01 08:26:00 |        2.75 |        17850 | United Kingdom |
|  3 |      536365 | 84029G      | KNITTED UNION FLAG HOT WATER BOTTLE |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |
|  4 |      536365 | 84029E      | RED WOOLLY HOTTIE WHITE HEART.      |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |

## Missing Value
Some Machine learning algorithms cannot handle missing value, So, to prevent error, I will calculate how much missing value in each column and decided which strategy should I implemented to handle missing value

```python
#sum missing value
missing_values = df.isnull().sum()

#calculate percent of missing value
percent_missing = df.isnull().sum() / len(df) * 100

#create dataframe
missing_table = pd.concat([missing_values, percent_missing],axis=1).reset_index()

#rename columns
missing_table = missing_table.rename(columns={'index':'name column', 0:'total missing', 1:'percent missing'})
missing_table['percent missing'] = round(missing_table['percent missing'],1)

#sort values
missing_table = missing_table.sort_values('percent missing', ascending=False)

missing_table
```
|    | name column   |   total missing |   percent missing |
|---:|:--------------|----------------:|------------------:|
|  6 | CustomerID    |          135080 |              24.9 |
|  2 | Description   |            1454 |               0.3 |
|  0 | InvoiceNo     |               0 |               0   |
|  1 | StockCode     |               0 |               0   |
|  3 | Quantity      |               0 |               0   |
|  4 | InvoiceDate   |               0 |               0   |
|  5 | UnitPrice     |               0 |               0   |
|  7 | Country       |               0 |               0   |

- CustomerID has a 24.9 percent missing value. Normally, we need to communicate this problem with Data Engineer or marketing team to fill missing customerID with actual CustomerID because remove 24,9 percent of data could omit important information that might be useful for cluster analysis. But, Since we don't have any information, missing value below 30 % and CustomerID contain every information about the customer, we will use data that has a customerID

- i will not change Descreption because i don't need that column for customer segmentation

```python
#remove missing value
new_df =df[pd.notnull(df['CustomerID'])]

new_df.shape
```
(406829, 8)

## Feature Engineering
For this part, i have:

- Create columns contains total price (Unit price multiply with quantity)
- remove quantity with negative value
- create columns contain information about customer is canceled their invoice or not
- split data in some columns, such as year, yearmonth, month, days and hours.

```python

#create columns contain total price
new_df['total price'] = new_df['UnitPrice'] * new_df['Quantity']

#remove quaantity with negative value
new_df = new_df[new_df['Quantity'] > 0]

#create columns to find the customer is canceled their buying or not0
new_df['InvoiceNo'] = new_df['InvoiceNo'].astype('str')

def is_cancel(datas):
  if 'C' in datas or 'c' in datas:
    return 1
  else:
    return 0

new_df['is_canceled'] = new_df['InvoiceNo'].apply(is_cancel)

# add the year, month, day , and hours columns for invoice
new_df['year'] = new_df.InvoiceDate.dt.year
new_df['yearmonth'] = new_df['InvoiceDate'].map(lambda x: 100*x.year + x.month)
new_df['month'] = new_df.InvoiceDate.dt.month
new_df['days'] = new_df.InvoiceDate.dt.dayofweek + 1
new_df['hour'] = new_df.InvoiceDate.dt.hour

new_df.head()
```
|    |   InvoiceNo | StockCode   | Description                         |   Quantity | InvoiceDate         |   UnitPrice |   CustomerID | Country        |   total price |   is_canceled |   year |   yearmonth |   month |   days |   hour |
|---:|------------:|:------------|:------------------------------------|-----------:|:--------------------|------------:|-------------:|:---------------|--------------:|--------------:|-------:|------------:|--------:|-------:|-------:|
|  0 |      536365 | 85123A      | WHITE HANGING HEART T-LIGHT HOLDER  |          6 | 2010-12-01 08:26:00 |        2.55 |        17850 | United Kingdom |         15.3  |             0 |   2010 |      201012 |      12 |      3 |      8 |
|  1 |      536365 | 71053       | WHITE METAL LANTERN                 |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |         20.34 |             0 |   2010 |      201012 |      12 |      3 |      8 |
|  2 |      536365 | 84406B      | CREAM CUPID HEARTS COAT HANGER      |          8 | 2010-12-01 08:26:00 |        2.75 |        17850 | United Kingdom |         22    |             0 |   2010 |      201012 |      12 |      3 |      8 |
|  3 |      536365 | 84029G      | KNITTED UNION FLAG HOT WATER BOTTLE |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |         20.34 |             0 |   2010 |      201012 |      12 |      3 |      8 |
|  4 |      536365 | 84029E      | RED WOOLLY HOTTIE WHITE HEART.      |          6 | 2010-12-01 08:26:00 |        3.39 |        17850 | United Kingdom |         20.34 |             0 |   2010 |      201012 |      12 |      3 |      8 |

